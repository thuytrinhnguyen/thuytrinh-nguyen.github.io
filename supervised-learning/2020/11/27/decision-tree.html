<!DOCTYPE html>
<html lang="en">

  <head>
    
      






    

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta property="og:image" content="https://raw.githubusercontent.com/thuytrinhnguyen/thuytrinhnguyen.github.io/main/assets/images/learning-rate-gradient-descent.png">
    <title>Decision Tree</title>

    <meta name="description" content="This post covers the fundamental concepts in Decision Tree for both regression and classification purposes. From growing a full tree using different splittin...">

    <meta content="Chloe's Tech Journey" property="og:site_name">
    
        <meta content="Decision Tree" property="og:title">
    
    
        <meta content="article" property="og:type">
    
    
        <meta content="This post covers the fundamental concepts in Decision Tree for both regression and classification purposes. From growing a full tree using different splitting criteria to pruning the tree to prevent overfitting, we will go through it all in this blog entry. So let’s buckle up!" property="og:description">
    
    
        <meta content="http://localhost:4000/supervised-learning/2020/11/27/decision-tree.html" property="og:url">
    
    
        <meta content="2020-11-27T15:44:00+11:00" property="article:published_time">
        <meta content="http://localhost:4000/about/" property="article:author">
    
    
    
        
        <meta content="decision-tree" property="article:tag">
        
        <meta content="classification" property="article:tag">
        
        <meta content="regression" property="article:tag">
        
    

    <link rel="shortcut icon" href="/assets/favicon_cactus.ico">
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/supervised-learning/2020/11/27/decision-tree.html">

    <!-- For Latex -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

    <!-- Google Analytics -->
    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-8161570-6', 'auto');
        ga('send', 'pageview');
    </script>

    <!-- For Facebook share button -->
    <div id="fb-root"></div>
    <script>
      (function(d, s, id) {
        var js, fjs = d.getElementsByTagName(s)[0];
        if (d.getElementById(id)) return;
        js = d.createElement(s); js.id = id;
        js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.9";
        fjs.parentNode.insertBefore(js, fjs);
      }(document, 'script', 'facebook-jssdk'));
    </script>

    <!-- Twitter cards -->
    <meta name="twitter:site"    content="@">
    <meta name="twitter:creator" content="@Chloe Nguyen">
    <meta name="twitter:title"   content="Decision Tree">

    
        <meta name="twitter:description" content="<blockquote>
  <p>This post covers the fundamental concepts in Decision Tree for both regression and classification purposes. From growing a full tree using different splitting criteria to pruning the tree to prevent overfitting, we will go through it all in this blog entry. So let’s buckle up!</p>
</blockquote>

">
    

    
        <meta name="twitter:card"  content="summary">
        <meta name="twitter:image" content="">
    
    <!-- end of Twitter cards -->

</head>


  <body>

    <header class="site-header" role="banner" id='header-bar'>

    <div class="wrapper">
        
        <a class="site-title" href="/">Chloe&#39;s Tech Journey</a>

        <!-- <nav class="site-nav">
            <a class="page-link" href="http://lilianweng.github.io" target="_blank">&#x1f349; About</a>
        </nav> -->
        <nav class="site-nav">
            <a class="page-link" href="/contact.html">&#x1f984; Contact</a>
        </nav>
        <nav class="site-nav">
            <a class="page-link" href="/FAQ.html">&#x1F64B; FAQ</a>
        </nav>
        <!-- <nav class="site-nav">
            <a class="page-link" href="/log.html">&#x231b; Log</a>
        </nav> -->
        <nav class="site-nav">
            <a class="page-link" href="/archive.html">&#x231b; Archive</a>
        </nav>

    </div>

</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Decision Tree</h1>
    <p class="post-meta">

      <time datetime="2020-11-27T15:44:00+11:00" itemprop="datePublished">
        
        Nov 27, 2020
      </time>

      <span itemprop="author" itemscope itemtype="http://schema.org/Person">
        by <span itemprop="name">Chloe Nguyen</span>
      </span>

      <span>
        
          
          <a class="post-tag" href="/myblog/tag/decision-tree"><nobr>decision-tree</nobr>&nbsp;</a>
        
          
          <a class="post-tag" href="/myblog/tag/classification"><nobr>classification</nobr>&nbsp;</a>
        
          
          <a class="post-tag" href="/myblog/tag/regression"><nobr>regression</nobr>&nbsp;</a>
        
      </span>
      <!--
      <span class="share-buttons">
        <span class="share-button"><a class="twitter-share-button" href="https://twitter.com/share" data-show-count="false">Tweet</a><script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></span>

        <span class="share-button"><span class="fb-like" data-href="/supervised-learning/2020/11/27/decision-tree.html" data-layout="button_count" data-action="like" data-size="small" data-show-faces="false" data-share="true"></span></span>
      </span>
      <div style="clear: both;"/>
      -->

    </p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <blockquote>
  <p>This post covers the fundamental concepts in Decision Tree for both regression and classification purposes. From growing a full tree using different splitting criteria to pruning the tree to prevent overfitting, we will go through it all in this blog entry. So let’s buckle up!</p>
</blockquote>

<!--more-->

<p><mark><b>Highlights</b></mark></p>

<ul class="table-of-content" id="markdown-toc">
  <li><a href="#purpose" id="markdown-toc-purpose">Purpose</a></li>
  <li><a href="#building-decision-tree" id="markdown-toc-building-decision-tree">Building Decision Tree</a>    <ul>
      <li><a href="#regression-tree-measure-of-purity" id="markdown-toc-regression-tree-measure-of-purity">Regression tree: Measure of purity</a></li>
      <li><a href="#classification-tree-measure-of-purity" id="markdown-toc-classification-tree-measure-of-purity">Classification tree: Measure of purity</a></li>
    </ul>
  </li>
  <li><a href="#how-to-build-a-decision-tree" id="markdown-toc-how-to-build-a-decision-tree">How to build a decision tree</a>    <ul>
      <li><a href="#1-choose-the-root-node" id="markdown-toc-1-choose-the-root-node">1. Choose the root node</a></li>
      <li><a href="#deal-with-numerical-data-dont-include-everything---find-a-breaking-point--half-the-option" id="markdown-toc-deal-with-numerical-data-dont-include-everything---find-a-breaking-point--half-the-option">Deal with numerical data (Dont include everything - Find a breaking point =&gt; half the option)</a></li>
      <li><a href="#2" id="markdown-toc-2">2.</a></li>
    </ul>
  </li>
</ul>

<h2 id="purpose">Purpose</h2>

<p>Decision tree is a popular technique in supervised learning. The full name of this technique is CART, which stands of Classification-And-Regression-Tree. From its name you can probably guess that Decision tree is capable of both <strong>classification</strong> and <strong>regression</strong> problems. In this post, I will walk you through both Regression tree and Classification tree, which share many core ideas.</p>

<p><strong>So, in general, what does Decision tree do?</strong></p>

<p>Decision tree builds a set of rules that partition the data in half repeatedly. The ultimate goal is to stratify observations into segments to either classify or predict values of future data points.</p>

<figure class="width_500">
<p><img src="/assets/images/decision-tree-reg.png" alt="" /></p>
  <figcaption>Fig. 1. Example of a regression tree</figcaption>
</figure>

<p>Fig. 1. demonstrates a regression tree to predict house prices where each leaf node (i.e. the last node on each branch) is the <strong>average</strong> price of the houses matching the previous conditions. For example, the mean price of all houses that (1) locate in “Inner city” area and (2) have no more than 2 bedrooms, is $400K. Using this regression tree, if a future data points falls into this group, we can predict its price to be $400K.</p>

<figure class="width_500">
<p><img src="/assets/images/decision-tree-classification.png" alt="" /></p>
  <figcaption>Fig. 2. Example of a classification tree</figcaption>
</figure>

<p>Classification trees are slightly different as their leaves are categories instead of numerical values. Fig. 2. shows that although the leaf nodes in classification trees cannot be numerical, we can still include numerical predictors in our tree as internal nodes (e.g. Price &lt; $700K). We will discuss the details of how to work numerical independent variables in decision trees in later section. For now, looking at our example, if a house (1) is outside “Inner city” and (2) its price is greater than $700k, we will guess that it is a Beach House.</p>

<h2 id="building-decision-tree">Building Decision Tree</h2>

<p>Decision trees of both regression and classification type follow the same procedure.</p>

<figure>
<p><img src="/assets/images/decision-tree-question.png" alt="" /></p>
  <figcaption>Fig. 3. Questions to ask when building a tree</figcaption>
</figure>

<p>Fig. 3. illustrates the standard architecture of decision trees along with the questions that you may ask when constructing each section of the tree. In general, there are three main steps in building a tree that concern with the root node, internal nodes and leaf nodes.</p>

<p><strong>Step 1:</strong> Define a root node</p>

<p><strong>Step 2:</strong> Expand the tree (recursively)</p>

<p><strong>Step 3:</strong> Decide when to stop</p>

<p>Recall that our goal is to have final groups that are pure (i.e. all members of the group belong to the same class). Therefore, we need to define a <strong>measure of purity</strong> to compare splitting options, which will guide us through all 3 steps listed above.</p>

<h3 id="regression-tree-measure-of-purity">Regression tree: Measure of purity</h3>

<p>To decide which independent variable is the best to sort the data, we use Residual Sum of Square (RSS) as the measure of purity.</p>

\[RSS = \sum_{j}^{J}\sum_{i \in j}(y_i - \bar{y_j})^2\]

<figure>
<p><img src="/assets/images/decision-tree-boundary.png" alt="" /></p>
  <figcaption>Fig. 4. Distance to city and No of bedrooms to predict House price</figcaption>
</figure>

<h3 id="classification-tree-measure-of-purity">Classification tree: Measure of purity</h3>

<ul>
  <li>
    <p>Ask questions</p>
  </li>
  <li>
    <p>Classify the data based on the answer</p>
  </li>
</ul>

<p>Example</p>

<p>Yes/No</p>

<p>Rank (score 1, 2)</p>

<ul>
  <li>
    <p>Leaves can be numeric or categorical</p>
  </li>
  <li>
    <p>Can have different questions on each side</p>
  </li>
</ul>

<h2 id="how-to-build-a-decision-tree">How to build a decision tree</h2>

<h3 id="1-choose-the-root-node">1. Choose the root node</h3>

<ul>
  <li>
    <p>How well a variable predict</p>
  </li>
  <li>
    <p>Measure Impurity: Which one separate the classes the best (less mixed)</p>
  </li>
</ul>

<p>Calculate GINI… for all variables</p>

<p>Choose the variable with lowest GINI (impurity) to be the root node</p>

<p><a href="https://www.youtube.com/watch?v=7VeUPuFGJHk&amp;t=1s">StatQuest</a></p>

<p>If the impurity does not reduce after another step =&gt; Leaf node (13:42)</p>

<p><strong>GINI</strong></p>

\[G = 1 - \sum_{i} p_{c_i} ^{2}\]

<p><strong>Entropy</strong></p>

\[H = - \sum_{i}p(c_i) \times log_{2}p(c_i)\]

<h3 id="deal-with-numerical-data-dont-include-everything---find-a-breaking-point--half-the-option">Deal with numerical data (Dont include everything - Find a breaking point =&gt; half the option)</h3>

<ol>
  <li>Continuous</li>
</ol>

<p>Sort data</p>

<p>Calculate average weight of every 2 data points = Breaking point</p>

<p>Calculate Gini for all breaking points</p>

<p>Choose one with the lowest Gini</p>

<ol>
  <li>Discrete (ranking 1 2 3)</li>
</ol>

<p>Calculate gini for each rank (not average values)</p>

<h3 id="2">2.</h3>


  </div>


  <div class="page-navigation">
    
      <a class="prev" href="/2020/11/23/entropy.html">&larr; Entropy - Information Gain Theory</a>
    

    
      <a class="next" href="/2020/11/29/kaggle-housing-price.html">Kaggle Challenge - Predict Housing Prices &rarr;</a>
    
  </div>

</article>

      </div>
    </main>

    <div style="clear: both;"/>
<footer class="site-footer">
    2019 &copy; Built by <a href="https://jekyllrb.com/" target="_blank">Jekyll</a> and <a href="https://github.com/jekyll/minima/" target="_blank">minima</a> | View <a href="https://github.com/thuytrinhnguyen/myblog" target="_blank">this</a> on Github | <a href="/tags.html">Tags</a> | <a href="/contact.html">Contact</a> | <a href="/FAQ.html">FAQ</a>

    <p>
        <a href="/feed.xml" target="_blank">
            <img src="/assets/images/logo_rss.png" />
        </a>
        <a href=" " target="_blank">
            <img src="/assets/images/logo_scholar.png" />
        </a>
        <a href=" " target="_blank">
            <img src="/assets/images/logo_github.png" />
        </a>
        <a href=" " target="_blank">
            <img src="/assets/images/logo_instagram.png" />
        </a>
    </p>
</footer>


  </body>

</html>
